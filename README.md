# ğŸ›°ï¸ Enhanced SAR Autoencoder para DetecÃ§Ã£o de MudanÃ§as

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um **autoencoder U-Net** especializado para detecÃ§Ã£o de mudanÃ§as em imagens SAR (Synthetic Aperture Radar) multi-temporais do Sentinel-1. A rede neural utiliza mecanismos de atenÃ§Ã£o temporal e espacial para identificar mudanÃ§as na superfÃ­cie terrestre, como enchentes, desmatamento e alteraÃ§Ãµes de uso do solo.

A rede Enhanced SAR Autoencoder Ã© um Uâ€‘Net adaptado para sÃ©ries temporais Sentinelâ€‘1, com 64 canais de entrada (32 Ã©pocas Ã— 2 bandas VV/VH) definidos globalmente para lidar com a dimensÃ£o temporal e espectral do SAR. O encoder empilha blocos residuais e mecanismos de atenÃ§Ã£o: o primeiro bloco aplica atenÃ§Ã£o espacial para destacar regiÃµes relevantes no mapa (Conv2D 7Ã—7 + sigmoid), enquanto o segundo utiliza atenÃ§Ã£o temporal ao projetar cada canal em pesos normalizados via softmax, realÃ§ando perÃ­odos crÃ­ticos da sÃ©rie. Esses mÃ³dulos sÃ£o integrados ao Uâ€‘Net com skip connections, formando um autoencoder profundo que comprime as features no bottleneck e as reconstrÃ³i simetricamente no decoder.

Durante o treinamento, a funÃ§Ã£o ChangeDetectionLoss combina erro de reconstruÃ§Ã£o (MSE) e consistÃªncia temporal (L1 entre diferenÃ§as consecutivas), pressionando a rede a aprender padrÃµes â€œnormaisâ€ e manter coerÃªncia ao longo do tempo. Na fase de inferÃªncia, o analisador calcula o erro absoluto entre entrada e reconstruÃ§Ã£o para cada pixel; um limiar baseado em percentil (por padrÃ£o, 95%) gera um mapa binÃ¡rio de mudanÃ§as, com pÃ³s-processamento morfolÃ³gico para reduzir ruÃ­dos. Assim, regiÃµes com alto erro indicam alteraÃ§Ãµes significativas na sÃ©rie temporal SAR, como enchentes ou desmatamentos, sendo realÃ§adas pela atenÃ§Ã£o espacial e temporal que foca nos locais e instantes mais impactados.

## ğŸ§  Arquitetura da Rede Neural

### 1. Estrutura do Autoencoder

A rede Ã© baseada na arquitetura **U-Net** com as seguintes caracterÃ­sticas:

```
Input: [Batch, 64, 448, 336]  â†’ 64 canais (32 timesteps Ã— 2 bandas SAR)
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          ENCODER BRANCH             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚ Conv2D(64â†’64) + BatchNorm + ReLUâ”‚ â”‚  Skip Connection 1
    â”‚  â”‚ ResidualBlock + SpatialAttentionâ”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚
    â”‚             MaxPool(2Ã—2)             â”‚              â”‚
    â”‚                 â†“                    â”‚              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚
    â”‚  â”‚Conv2D(64â†’128) + BatchNorm + ReLUâ”‚ â”‚ Skip Connection 2
    â”‚  â”‚ResidualBlock + TemporalAttentionâ”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚ â”‚
    â”‚             MaxPool(2Ã—2)             â”‚              â”‚ â”‚
    â”‚                 â†“                    â”‚              â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚ â”‚
    â”‚  â”‚Conv2D(128â†’256) + BatchNorm+ReLU â”‚ â”‚ Skip Connection 3
    â”‚  â”‚ ResidualBlock + SpatialAttentionâ”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚ â”‚ â”‚
    â”‚             MaxPool(2Ã—2)             â”‚              â”‚ â”‚ â”‚
    â”‚                 â†“                    â”‚              â”‚ â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚ â”‚ â”‚
    â”‚  â”‚Conv2D(256â†’512) + BatchNorm+ReLU â”‚ â”‚ Skip Connection 4
    â”‚  â”‚       ResidualBlock             â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”¼â”€â”
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚ â”‚ â”‚ â”‚
    â”‚             MaxPool(2Ã—2)             â”‚              â”‚ â”‚ â”‚ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”˜              â”‚ â”‚ â”‚ â”‚
                        â†“                                 â”‚ â”‚ â”‚ â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”              â”‚ â”‚ â”‚ â”‚
    â”‚           BOTTLENECK                 â”‚              â”‚ â”‚ â”‚ â”‚
    â”‚  Conv2D(512â†’1024) + BatchNorm+ReLU   â”‚              â”‚ â”‚ â”‚ â”‚
    â”‚  ResidualBlock + Dropout(0.3)        â”‚              â”‚ â”‚ â”‚ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”˜              â”‚ â”‚ â”‚ â”‚
                        â†“                                 â”‚ â”‚ â”‚ â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”              â”‚ â”‚ â”‚ â”‚
    â”‚          DECODER BRANCH              â”‚              â”‚ â”‚ â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚ â”‚ â”‚ â”‚
    â”‚  â”‚  ConvTranspose2D(1024â†’512)      â”‚ â”‚              â”‚ â”‚ â”‚ â”‚
    â”‚  â”‚  Concatenate with Skip 4  â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
    â”‚  â”‚  Conv2D + ResidualBlock         â”‚ â”‚                â”‚ â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                â”‚ â”‚ â”‚
    â”‚                 â†“                    â”‚                â”‚ â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                â”‚ â”‚ â”‚
    â”‚  â”‚  ConvTranspose2D(512â†’256)       â”‚ â”‚                â”‚ â”‚ â”‚
    â”‚  â”‚  Concatenate with Skip 3  â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
    â”‚  â”‚  Conv2D + ResidualBlock         â”‚ â”‚                  â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                  â”‚ â”‚
    â”‚                 â†“                    â”‚                  â”‚ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                  â”‚ â”‚
    â”‚  â”‚  ConvTranspose2D(256â†’128)       â”‚ â”‚                  â”‚ â”‚
    â”‚  â”‚  Concatenate with Skip 2  â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚  â”‚  Conv2D + ResidualBlock         â”‚ â”‚                    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                    â”‚
    â”‚                 â†“                    â”‚                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                    â”‚
    â”‚  â”‚  ConvTranspose2D(128â†’64)        â”‚ â”‚                    â”‚
    â”‚  â”‚  Concatenate with Skip 1  â”€â”€â”€â”€â”€â”€â”¼â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚  â”‚  Conv2D + ResidualBlock         â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚                 â†“                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚      Conv2D(64â†’64)              â”‚ â”‚
    â”‚  â”‚     Output Layer                â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”˜
                        â†“
Output: [Batch, 64, 448, 336]  â†’ ReconstruÃ§Ã£o da imagem original
```

### 2. Componentes Especializados

#### ğŸ¯ **Mecanismo de AtenÃ§Ã£o Espacial**
```python
class SpatialAttention(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv = nn.Conv2d(channels, 1, kernel_size=7, padding=3)
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        attention = self.conv(x)          # Gera mapa de atenÃ§Ã£o
        attention = self.sigmoid(attention) # Normaliza [0,1]
        return x * attention              # Aplica atenÃ§Ã£o
```

**FunÃ§Ã£o:** Foca automaticamente em regiÃµes espaciais importantes para detecÃ§Ã£o de mudanÃ§as.

#### â° **Mecanismo de AtenÃ§Ã£o Temporal**
```python
class TemporalAttention(nn.Module):
    def __init__(self, channels, temporal_steps):
        super().__init__()
        self.temporal_steps = temporal_steps
        self.temporal_fc = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(channels, temporal_steps),
            nn.Softmax(dim=1)
        )
        
    def forward(self, x):
        # Calcula pesos para cada timestep
        temporal_weights = self.temporal_fc(x)
        # Aplica pesos aos canais temporais
        return weighted_temporal_features
```

**FunÃ§Ã£o:** Identifica automaticamente quais perÃ­odos temporais sÃ£o mais relevantes para detectar mudanÃ§as.

#### ğŸ”„ **Blocos Residuais**
```python
class ResidualBlock(nn.Module):
    def forward(self, x):
        residual = x
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual  # ConexÃ£o residual
        return self.relu(out)
```

**FunÃ§Ã£o:** Facilita o treinamento de redes profundas e evita o problema do gradiente que desaparece.

## ğŸ” Como a Rede Detecta MudanÃ§as

### 1. PrincÃ­pio do Autoencoder para DetecÃ§Ã£o de MudanÃ§as

O autoencoder funciona baseado no princÃ­pio de **"aprender o normal"**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Imagem Original   â”‚â”€â”€â”€â–¶â”‚   Autoencoder    â”‚â”€â”€â”€â–¶â”‚ Imagem ReconstruÃ­da â”‚
â”‚   [Todas as Ã©pocas] â”‚    â”‚ [Aprende padrÃµes â”‚    â”‚  [PadrÃµes normais]  â”‚
â”‚                     â”‚    â”‚     normais]     â”‚    â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                                    â”‚
           â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Erro de Reconst. â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ |Original - Recon|â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ Mapa de MudanÃ§as â”‚
                            â”‚ (Alto erro =     â”‚
                            â”‚  MudanÃ§a)        â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Processo de DetecÃ§Ã£o

#### **Etapa 1: Treinamento**
- A rede aprende a reconstruir **apenas Ã¡reas sem mudanÃ§as**
- Dados de treinamento contÃªm pixels "estÃ¡veis" da sÃ©rie temporal
- A rede memoriza padrÃµes espectrais e temporais normais

#### **Etapa 2: InferÃªncia**
```python
def detect_changes(original_image, model):
    # 1. NormalizaÃ§Ã£o temporal por banda
    normalized = normalize_temporal_bands(original_image)
    
    # 2. ReconstruÃ§Ã£o pela rede
    with torch.no_grad():
        reconstruction = model(normalized)
    
    # 3. CÃ¡lculo do erro de reconstruÃ§Ã£o
    error = torch.mean((original_image - reconstruction) ** 2, dim=1)
    
    # 4. Threshold para detecÃ§Ã£o binÃ¡ria
    threshold = torch.quantile(error, 0.95)  # 95Â° percentil
    changes = error > threshold
    
    return error, changes
```

#### **Etapa 3: InterpretaÃ§Ã£o**
- **Erro baixo**: Ãrea reconstruÃ­da corretamente â†’ **Sem mudanÃ§a**
- **Erro alto**: Ãrea mal reconstruÃ­da â†’ **MudanÃ§a detectada**

### 3. Tratamento Temporal

#### **Estrutura dos Dados SAR**
```
Input Tensor: [Batch, 64, Height, Width]
                 â†“
InterpretaÃ§Ã£o: [Batch, 32Ã—2, Height, Width]
                        â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                â”‚               â”‚
           32 Timesteps    2 Bandas
           (Sentinel-1)    (VV, VH)
```

#### **NormalizaÃ§Ã£o Temporal por Banda**
```python
def temporal_normalize(image):
    # Reshape: [H, W, 64] â†’ [H, W, 32, 2]
    reshaped = image.reshape(H, W, 32, 2)
    
    for band in range(2):
        band_data = reshaped[:, :, :, band]  # [H, W, 32]
        
        if band == 0:  # Banda VV
            # Backscatter mais forte, range tÃ­pico: [-25, 5] dB
            clipped = np.clip(band_data, -25, 5)
            normalized = (clipped + 25) / 30  # [0, 1]
        else:  # Banda VH
            # Backscatter mais fraco, range tÃ­pico: [-35, -5] dB
            clipped = np.clip(band_data, -35, -5) 
            normalized = (clipped + 35) / 30  # [0, 1]
        
        reshaped[:, :, :, band] = normalized
    
    return reshaped.reshape(H, W, 64)
```

## ğŸ¯ FunÃ§Ã£o de Perda Especializada

### **ChangeDetectionLoss**

A rede usa uma funÃ§Ã£o de perda combinada que otimiza dois objetivos:

```python
class ChangeDetectionLoss(nn.Module):
    def forward(self, pred, target):
        # 1. Perda de ReconstruÃ§Ã£o (MSE)
        reconstruction_loss = MSE(pred, target)
        
        # 2. Perda de ConsistÃªncia Temporal
        temporal_loss = temporal_consistency(pred, target)
        
        # 3. CombinaÃ§Ã£o Ponderada
        total_loss = Î± Ã— reconstruction_loss + Î² Ã— temporal_loss
        
        return total_loss
```

#### **1. Perda de ReconstruÃ§Ã£o (Î± = 0.8)**
- **Objetivo**: Minimizar erro pixel-a-pixel
- **MatemÃ¡tica**: `MSE = mean((original - reconstructed)Â²)`
- **FunÃ§Ã£o**: ForÃ§a a rede a reconstruir fielmente Ã¡reas normais

#### **2. Perda de ConsistÃªncia Temporal (Î² = 0.2)**
```python
def temporal_consistency_loss(pred, target):
    # Reshape: [B, 64, H, W] â†’ [B, 32, 2, H, W]
    pred_temporal = pred.view(B, 32, 2, H, W)
    target_temporal = target.view(B, 32, 2, H, W)
    
    # DiferenÃ§as temporais consecutivas
    pred_diff = pred_temporal[:, 1:] - pred_temporal[:, :-1]
    target_diff = target_temporal[:, 1:] - target_temporal[:, :-1]
    
    # L1 loss nas diferenÃ§as temporais
    return L1(pred_diff, target_diff)
```
- **Objetivo**: Manter coerÃªncia temporal na reconstruÃ§Ã£o
- **FunÃ§Ã£o**: Evita artefatos temporais e melhora estabilidade

## âš™ï¸ Pipeline de Processamento

### **1. PrÃ©-processamento**
```python
# CorreÃ§Ã£o de valores invÃ¡lidos
image = np.nan_to_num(image, nan=median_value)

# NormalizaÃ§Ã£o robusta por percentis
p2, p98 = np.percentile(valid_pixels, [2, 98])
normalized = (image - p2) / (p98 - p2)
```

### **2. Arquitetura de Processamento**
```
Imagem SAR Original
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CorreÃ§Ã£o de NaN   â”‚ â† SubstituiÃ§Ã£o por mediana
â”‚ e valores Inf     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redimensionamento â”‚ â† Compatibilidade com U-Net
â”‚ 442Ã—330 â†’ 448Ã—336 â”‚   (mÃºltiplos de 16)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NormalizaÃ§Ã£o      â”‚ â† Por banda (VV/VH)
â”‚ Temporal          â”‚   Range [0,1]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ InferÃªncia        â”‚ â† Modelo U-Net + AtenÃ§Ã£o
â”‚ Neural Network    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CÃ¡lculo de Erro   â”‚ â† MSE pixel-wise
â”‚ de ReconstruÃ§Ã£o   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Threshold         â”‚ â† 95Â° percentil
â”‚ Adaptativo        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mapa de MudanÃ§as  â”‚ â† BinÃ¡rio + ContÃ­nuo
â”‚ Final             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **3. SaÃ­da Georreferenciada**
```python
# PreservaÃ§Ã£o de metadados geoespaciais
with rasterio.open('output.tif', 'w',
                   driver='GTiff',
                   height=original_height,
                   width=original_width,
                   count=1,
                   dtype=np.uint8,
                   crs=original_crs,        # Sistema de coordenadas
                   transform=original_transform  # GeotransformaÃ§Ã£o
                  ) as dst:
    dst.write(change_map, 1)
```

## ğŸ“Š InterpretaÃ§Ã£o dos Resultados

### **MÃ©tricas de SaÃ­da**
- **Erro MÃ©dio**: Indica qualidade geral da reconstruÃ§Ã£o
- **Threshold Adaptativo**: Baseado no 95Â° percentil dos erros
- **Porcentagem de MudanÃ§as**: % da Ã¡rea total com mudanÃ§as detectadas
- **Mapa ContÃ­nuo**: Valores de erro [0, 1] para anÃ¡lise detalhada
- **Mapa BinÃ¡rio**: MudanÃ§as binÃ¡rias (0 = sem mudanÃ§a, 255 = mudanÃ§a)

### **Tipos de MudanÃ§as DetectÃ¡veis**
1. **Enchentes**: MudanÃ§a drÃ¡stica em backscatter por presenÃ§a de Ã¡gua
2. **Desmatamento**: AlteraÃ§Ã£o de textura e intensidade SAR
3. **ConstruÃ§Ãµes**: Aumento significativo de backscatter
4. **MudanÃ§as AgrÃ­colas**: VariaÃ§Ãµes sazonais em cultivos
5. **Deslizamentos**: AlteraÃ§Ãµes topogrÃ¡ficas e de cobertura

### **Vantagens da Abordagem**
- âœ… **NÃ£o supervisionada**: NÃ£o requer dados rotulados de mudanÃ§as
- âœ… **Adaptativa**: Threshold automÃ¡tico baseado nos dados
- âœ… **Temporal**: ExploraÃ§Ã£o completa da dimensÃ£o temporal
- âœ… **Robusta**: Mecanismos de atenÃ§Ã£o e normalizaÃ§Ã£o adaptativa
- âœ… **EscalÃ¡vel**: Processamento de imagens inteiras sem patches

## ğŸ”¬ Aspectos TÃ©cnicos AvanÃ§ados

### **Attention Mechanisms**
- **Spatial Attention**: Kernel 7Ã—7 para captura de contexto espacial
- **Temporal Attention**: Softmax sobre 32 timesteps para seleÃ§Ã£o temporal
- **IntegraÃ§Ã£o**: Aplicada em diferentes nÃ­veis da rede para mÃ¡xima efetividade

### **OtimizaÃ§Ã£o e RegularizaÃ§Ã£o**
- **Optimizer**: AdamW com weight decay (1e-5)
- **Learning Rate**: 2e-4 com ReduceLROnPlateau scheduler
- **Gradient Clipping**: max_norm=1.0 para estabilidade
- **Dropout**: 0.3 no bottleneck para generalizaÃ§Ã£o
- **Early Stopping**: PaciÃªncia de 20 Ã©pocas

### **Compatibilidade de Dados**
- **Entrada**: Multi-temporal SAR (32 timesteps Ã— 2 bandas)
- **Tipos**: Float32 para consistÃªncia numÃ©rica
- **DimensÃµes**: CompatÃ­vel com U-Net (mÃºltiplos de 16)
- **Formato**: GeoTIFF com preservaÃ§Ã£o de CRS e geotransformaÃ§Ã£o

---

**Desenvolvido com**: PyTorch 2.8.0, Rasterio 1.4.3, Albumentations 2.0.8
**Suporte**: CUDA para aceleraÃ§Ã£o GPU, processamento de imagens SAR Sentinel-1
**AplicaÃ§Ãµes**: Monitoramento ambiental, detecÃ§Ã£o de desastres, anÃ¡lise de LULC
